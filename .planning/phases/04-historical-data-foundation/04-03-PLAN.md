---
phase: 04-historical-data-foundation
plan: 03
type: execute
wave: 3
depends_on: ["04-02"]
files_modified:
  - src/bot/orchestrator.py
  - src/bot/main.py
  - src/bot/dashboard/templates/partials/data_status.html
  - src/bot/dashboard/routes/api.py
  - src/bot/dashboard/update_loop.py
  - src/bot/dashboard/templates/base.html
autonomous: false

must_haves:
  truths:
    - "Bot fetches all missing historical data on startup before entering the trading loop"
    - "Bot waits for historical data fetch to complete before starting trading (blocks startup)"
    - "Incremental data updates happen on each scan cycle automatically"
    - "Dashboard shows data status: pairs tracked, total records, date range, last sync time"
    - "Dashboard shows live fetch progress during initial loading"
    - "Data quality issues appear as warnings in logs and dashboard widget"
    - "Historical data feature is optional (| None = None injection pattern)"
  artifacts:
    - path: "src/bot/orchestrator.py"
      provides: "Orchestrator with historical data fetch on startup and incremental updates per cycle"
      contains: "_ensure_historical_data"
    - path: "src/bot/main.py"
      provides: "Wiring for HistoricalDatabase, HistoricalDataStore, HistoricalDataFetcher"
      contains: "HistoricalDataFetcher"
    - path: "src/bot/dashboard/templates/partials/data_status.html"
      provides: "Data status widget template"
    - path: "src/bot/dashboard/routes/api.py"
      provides: "/api/data-status endpoint"
      contains: "data-status"
    - path: "src/bot/dashboard/update_loop.py"
      provides: "Data status panel in WebSocket broadcast"
      contains: "data-status-panel"
  key_links:
    - from: "src/bot/orchestrator.py"
      to: "src/bot/data/fetcher.py"
      via: "self._data_fetcher.ensure_data_ready() on startup"
      pattern: "_data_fetcher\\.ensure_data_ready"
    - from: "src/bot/orchestrator.py"
      to: "src/bot/data/fetcher.py"
      via: "self._data_fetcher.incremental_update() on each cycle"
      pattern: "_data_fetcher\\.incremental_update"
    - from: "src/bot/orchestrator.py"
      to: "src/bot/data/pair_selector.py"
      via: "select_top_pairs() to determine which pairs to fetch"
      pattern: "select_top_pairs"
    - from: "src/bot/main.py"
      to: "src/bot/data/database.py"
      via: "Creates HistoricalDatabase and connects on startup"
      pattern: "HistoricalDatabase"
    - from: "src/bot/main.py"
      to: "src/bot/data/store.py"
      via: "Creates HistoricalDataStore with database"
      pattern: "HistoricalDataStore"
    - from: "src/bot/main.py"
      to: "src/bot/data/fetcher.py"
      via: "Creates HistoricalDataFetcher and injects into orchestrator"
      pattern: "HistoricalDataFetcher"
    - from: "src/bot/dashboard/routes/api.py"
      to: "src/bot/data/store.py"
      via: "Calls store.get_data_status() for dashboard widget"
      pattern: "get_data_status"
---

<objective>
Wire the historical data pipeline into the bot's startup sequence and scan loop, and add the dashboard data status widget for visibility.

Purpose: This plan makes the data layer operational. The orchestrator fetches all missing historical data before trading, appends new data on each scan cycle, and the dashboard shows live progress and status. The v1.1 feature-flag pattern (| None = None) ensures the bot still works without historical data configured.

Output: Fully integrated data pipeline that fetches on startup, updates incrementally, and shows status on the dashboard.
</objective>

<execution_context>
@/Users/luckleineschaars/.claude/get-shit-done/workflows/execute-plan.md
@/Users/luckleineschaars/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-historical-data-foundation/04-CONTEXT.md
@.planning/phases/04-historical-data-foundation/04-RESEARCH.md
@.planning/phases/04-historical-data-foundation/04-01-SUMMARY.md
@.planning/phases/04-historical-data-foundation/04-02-SUMMARY.md
@src/bot/orchestrator.py
@src/bot/main.py
@src/bot/dashboard/routes/api.py
@src/bot/dashboard/update_loop.py
@src/bot/dashboard/templates/base.html
</context>

<tasks>

<task type="auto">
  <name>Task 1: Orchestrator integration and main.py wiring</name>
  <files>
    src/bot/orchestrator.py
    src/bot/main.py
  </files>
  <action>
**Orchestrator changes (src/bot/orchestrator.py):**

1. Add optional constructor parameters following v1.1 convention (`| None = None` injection):
   - `data_fetcher: HistoricalDataFetcher | None = None`
   - `data_store: HistoricalDataStore | None = None`
   - `historical_settings: HistoricalDataSettings | None = None`
   - Store as `self._data_fetcher`, `self._data_store`, `self._historical_settings`

2. Add imports at top:
   ```python
   from bot.data.fetcher import HistoricalDataFetcher
   from bot.data.store import HistoricalDataStore
   from bot.data.pair_selector import select_top_pairs
   from bot.config import HistoricalDataSettings
   ```
   Use TYPE_CHECKING guard to avoid circular imports if needed.

3. Add `async _ensure_historical_data() -> None` method:
   - Guard: `if self._data_fetcher is None: return` (feature not enabled)
   - Get all funding rates from monitor: `all_rates = self._funding_monitor.get_all_funding_rates()`
   - If no rates available yet, log warning and return (monitor hasn't polled yet)
   - Select top pairs: `top_pairs = select_top_pairs(all_rates, count=self._historical_settings.top_pairs_count if self._historical_settings else 20)`
   - Update tracked pairs in store for each pair (call `self._data_store.update_tracked_pair()`)
   - Call: `await self._data_fetcher.ensure_data_ready(top_pairs)`
   - Log: `"historical_data_ready", pairs=len(top_pairs)`

4. Modify `start()` method:
   - After `await self._funding_monitor.start()` and before `self._running = True`:
   - Add: `await self._ensure_historical_data()`
   - This ensures the bot blocks on startup until historical data is ready (per user decision)

5. Add incremental update to `_autonomous_cycle()`:
   - After step 0 (APPLY runtime config) and before step 1 (SCAN):
   - Add a new step "0.5 UPDATE HISTORICAL DATA":
     ```python
     if self._data_fetcher is not None:
         all_rates = self._funding_monitor.get_all_funding_rates()
         if all_rates:
             top_pairs = select_top_pairs(all_rates, count=self._historical_settings.top_pairs_count if self._historical_settings else 20)
             await self._data_fetcher.incremental_update(top_pairs)
     ```
   - Wrap in try/except to not crash the cycle on data update failure (log warning)

6. Add `get_data_status() -> dict | None` method:
   - Guard: `if self._data_store is None: return None`
   - Return `await self._data_store.get_data_status()`

7. Track fetch progress state for dashboard:
   - Add `self._data_fetch_progress: dict | None = None` to __init__
   - Add property `data_fetch_progress` that returns current progress
   - Pass a progress callback to ensure_data_ready that updates this dict: `{"current_symbol": symbol, "current_index": i, "total": len(symbols), "status": "fetching"}`
   - Set to `{"status": "complete"}` when done

**main.py changes (src/bot/main.py):**

1. Add imports:
   ```python
   from bot.data.database import HistoricalDatabase
   from bot.data.store import HistoricalDataStore
   from bot.data.fetcher import HistoricalDataFetcher
   ```

2. In `_build_components()`, after creating the orchestrator (step 14) but before the emergency controller (step 15):
   - Add historical data components (conditional on settings.historical.enabled):
     ```python
     # 14.5. Create historical data components (optional v1.1 feature)
     historical_db = None
     data_store = None
     data_fetcher = None
     if settings.historical.enabled:
         historical_db = HistoricalDatabase(settings.historical.db_path)
         data_store = HistoricalDataStore(historical_db)
         data_fetcher = HistoricalDataFetcher(
             exchange=exchange_client,
             store=data_store,
             settings=settings.historical,
         )
     ```
   - Pass to orchestrator constructor: `data_fetcher=data_fetcher, data_store=data_store, historical_settings=settings.historical if settings.historical.enabled else None`

3. Add historical components to the returned dict:
   ```python
   "historical_db": historical_db,
   "data_store": data_store,
   "data_fetcher": data_fetcher,
   ```

4. In the `lifespan()` function:
   - After `await components["exchange_client"].connect()` and before starting the orchestrator:
     ```python
     # Connect historical database if enabled
     if components.get("historical_db"):
         await components["historical_db"].connect()
     ```
   - Store data_store on app.state for dashboard access:
     ```python
     app.state.data_store = components.get("data_store")
     ```
   - In shutdown section, after stopping orchestrator and before closing exchange:
     ```python
     # Close historical database if connected
     if components.get("historical_db"):
         await components["historical_db"].close()
     ```

5. In the non-dashboard `run()` path (else branch): Same pattern -- connect historical_db before orchestrator.start(), close in finally block.

IMPORTANT: The orchestrator's `_ensure_historical_data()` is called from `start()` which runs AFTER the exchange client is connected and the funding monitor has started. The funding monitor needs at least one poll cycle to have rates available. If no rates are available on the very first call, log a warning. The funding monitor's `start()` does an initial poll, so rates should be available immediately after `await self._funding_monitor.start()`.
  </action>
  <verify>
    - `python -c "from bot.orchestrator import Orchestrator; import inspect; sig = inspect.signature(Orchestrator.__init__); print('data_fetcher' in sig.parameters)"` shows True
    - `python -c "from bot.main import _build_components; print('main OK')"` succeeds
    - Existing tests pass: `python -m pytest tests/ -x -q` -- the None defaults mean no existing test should break
  </verify>
  <done>
    - Orchestrator accepts optional data_fetcher, data_store, historical_settings (None = feature disabled)
    - Orchestrator.start() calls _ensure_historical_data() before entering trading loop
    - Orchestrator._autonomous_cycle() calls incremental_update() on each iteration
    - main.py creates and wires HistoricalDatabase + Store + Fetcher when historical.enabled = true
    - Historical database connected/closed in lifespan lifecycle
    - All existing tests pass (None defaults preserve backward compatibility)
  </done>
</task>

<task type="auto">
  <name>Task 2: Dashboard data status widget</name>
  <files>
    src/bot/dashboard/templates/partials/data_status.html
    src/bot/dashboard/routes/api.py
    src/bot/dashboard/update_loop.py
    src/bot/dashboard/templates/base.html
  </files>
  <action>
1. Create `src/bot/dashboard/templates/partials/data_status.html`:
   - Match existing Tailwind card styling from other partials (dark theme, same bg/border patterns)
   - **Normal state** (data loaded): Show "Data Status" heading, then: pairs tracked count, total records (funding + OHLCV combined), date range (format: "Jan 2025 - Feb 2026"), last sync time (relative: "2m ago" / "just now")
   - **Loading state** (fetch in progress): Show progress text: "12/20 pairs -- Fetching ETH/USDT:USDT" with a simple progress indicator (e.g., CSS width percentage bar)
   - **Warning state** (quality issues): Yellow text/icon for data gaps or issues
   - **Disabled state** (historical data not enabled): Show "Historical data: disabled" in muted text
   - Template receives context: `data_status` (dict from get_data_status or None), `fetch_progress` (dict or None)
   - Use Jinja2 conditionals to switch between states

2. Add `/api/data-status` endpoint to `src/bot/dashboard/routes/api.py`:
   ```python
   @router.get("/data-status")
   async def get_data_status(request: Request) -> JSONResponse:
       """Data status for historical data widget."""
       data_store = getattr(request.app.state, "data_store", None)
       if data_store is None:
           return JSONResponse(content={"enabled": False})

       status = await data_store.get_data_status()
       orchestrator = request.app.state.orchestrator
       progress = orchestrator.data_fetch_progress

       result = {
           "enabled": True,
           **_decimal_to_str(status),
       }
       if progress:
           result["fetch_progress"] = progress

       return JSONResponse(content=result)
   ```

3. Add data status panel to `src/bot/dashboard/update_loop.py`:
   - In the `dashboard_update_loop` function, after the existing panel renders:
   - Get data_store from app.state (may be None)
   - If data_store is not None: `data_status = await data_store.get_data_status()` and `fetch_progress = orchestrator.data_fetch_progress`
   - If data_store is None: `data_status = None`, `fetch_progress = None`
   - Render the data_status partial: `tpl = env.get_template("partials/data_status.html"); html = tpl.render(data_status=data_status, fetch_progress=fetch_progress)`
   - Wrap in OOB swap div: `<div id="data-status-panel" hx-swap-oob="true">{html}</div>`
   - Append to fragments list

4. Add the data status panel to `src/bot/dashboard/templates/base.html`:
   - Find the existing top row of status cards (bot_status, balance, analytics)
   - Add a 4th card in the same row or add a new row below the top 3 cards
   - Add: `<div id="data-status-panel">{% include "partials/data_status.html" %}</div>`
   - If the top row is a 3-column grid, change to 4-column: `grid-cols-1 md:grid-cols-2 lg:grid-cols-4` (or keep 3-col and add data status as first item in the next row -- use your judgment for best visual layout)
   - Pass initial data_status and fetch_progress context to the page template render in pages.py if needed (or render as empty/loading state initially since WebSocket will populate it)
  </action>
  <verify>
    - Template exists and has no Jinja2 syntax errors: `python -c "from jinja2 import Environment, FileSystemLoader; env = Environment(loader=FileSystemLoader('src/bot/dashboard/templates')); tpl = env.get_template('partials/data_status.html'); print('template OK')"` succeeds
    - API endpoint accessible: Start the bot briefly or verify route registration: `python -c "from bot.dashboard.routes.api import router; routes = [r.path for r in router.routes]; print('/data-status' in [r.path for r in router.routes] if hasattr(router, 'routes') else 'check manually')"` or inspect route names
    - Update loop includes data status: grep for "data-status-panel" in update_loop.py
    - Existing tests pass: `python -m pytest tests/ -x -q`
  </verify>
  <done>
    - Dashboard shows "Data Status" widget with pairs tracked, total records, date range, last sync time
    - During initial fetch, widget shows live progress (pair X of Y)
    - /api/data-status JSON endpoint returns full data status
    - Widget updates via WebSocket along with all other panels
    - When historical data is disabled, widget shows "disabled" state
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: Verify data pipeline end-to-end</name>
  <files>none</files>
  <action>
CHECKPOINT: Human verification of the complete historical data pipeline.

What was built: Complete historical data pipeline -- SQLite persistence, paginated Bybit API fetching with retry/resume, orchestrator integration (startup block + incremental updates), and dashboard data status widget.

Steps to verify:
1. Start the bot: `funding-arb` (or `python -m bot.main`)
2. Observe startup logs -- should see:
   - "fetching_historical_data" messages with per-pair progress (e.g., "1/20", "2/20")
   - "funding_fetch_progress" and "ohlcv_fetch_progress" messages
   - "historical_data_ready" message before trading loop starts
3. Open dashboard at http://localhost:8080
4. Verify "Data Status" widget shows: pairs tracked (20), total records count, date range, last sync time
5. Stop the bot (Ctrl+C), then restart
6. On restart, verify it resumes quickly (no re-fetching -- should see "historical_data_ready" almost immediately since data persists in SQLite)
7. Verify the SQLite database file exists at `data/historical.db` (or configured path)
8. (Optional) Check no 429 errors in logs during initial fetch

If using paper mode without API keys: historical data endpoints are public (market data), so they should work even without API keys configured.
  </action>
  <verify>User confirms all 8 verification steps pass.</verify>
  <done>User types "approved" confirming data fetches, persists, resumes correctly, and dashboard shows status. Or user describes issues for remediation.</done>
</task>

</tasks>

<verification>
- Bot starts, fetches historical data, then enters trading loop
- Dashboard data status widget shows correct information
- Restart does not re-fetch existing data (resume from fetch_state)
- No 429 rate limit errors during initial bulk fetch
- All existing tests pass: `python -m pytest tests/ -x -q`
</verification>

<success_criteria>
- Historical data fetch blocks startup until complete (per user decision)
- Incremental updates run on each scan cycle
- Dashboard shows live fetch progress and data status
- SQLite database persists across restarts
- Feature is optional via historical.enabled setting
- All 5 phase success criteria from ROADMAP.md are met
</success_criteria>

<output>
After completion, create `.planning/phases/04-historical-data-foundation/04-03-SUMMARY.md`
</output>
